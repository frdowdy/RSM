---
title: "RSM_code"
output:
  html_document: default
  html_notebook: default
---

First we're going to set up R to to our target directory and clear the workspace.
```{r setup}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, 
                      message = FALSE,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = TRUE,
                      fig.path="Figures/",  # Set the figure options
                      fig.align = "center",
                      dev='png')

```

Clear RStudio
```{r clear}
  # cat(rep("\n",50)) # Clear Console
  rm(list=ls(all=TRUE)) # clear workspace
  graphics.off() # closes all graphics
```

Install function for needed packages
```{r packages function, message = FALSE, warning=FALSE}
   
  packages<-function(x){
    x<-as.character(match.call()[[2]])
    if (!require(x,character.only=TRUE)){
      install.packages(pkgs=x,repos="http://cran.r-project.org")
      require(x,character.only=TRUE)
    }
  }
  packages(rsm)
  packages(tidyverse)
  packages(pracma)
```


```{r get data, message = FALSE, warning=FALSE}
# https://cran.r-project.org/web/packages/rsm/vignettes/rsm.pdf
packages(XLConnect)
data <- readWorksheetFromFile("preliminary_RSM.xlsx",sheet=1)

# Withhold validation points from dataset
data_training <- data[1:13,]
```

Let's try it with our previous data set:
```{r generate RSM model for cycle 4}
rsm4 <- rsm(voltage_cycle_4 ~ SO(temp, acetate), data = data_training)
summary(rsm4)
```
Let's try visualizing these results.
```{r voltage_cycle_4}
persp(rsm4, ~ temp + acetate, col = rainbow(50), contours = "colors")
contour(rsm4, ~ temp + acetate, col = rainbow(50), contours = "colors")


packages(ggplot2)
packages(ggthemes)
packages(cowplot)
plot_acetate <- ggplot(data_training, aes(acetate, voltage_cycle_4)) + geom_point() + theme_few()
plot_temp <- ggplot(data_training, aes(temp, voltage_cycle_4)) + geom_point() + theme_few() 
plot_grid(plot_acetate, plot_temp, align='h', labels=c('a', 'b'))
```
Note that we could also plot this with other packages using plot.it=false
Now let's try this with our most recent data set.
```{r voltage_cycle_5}
rsm5 <- rsm(voltage_cycle_5 ~ SO(temp, acetate), data = data_training)
summary(rsm5)
persp(rsm5, ~ temp + acetate, col = rainbow(50), contours = "colors")
contour(rsm5, ~ temp + acetate, col = rainbow(50), contours = "colors")

#Look at slices against each factor
plot_acetate <- ggplot(data_training, aes(acetate, voltage_cycle_5)) + geom_point() + theme_few()
plot_temp <- ggplot(data_training, aes(temp, voltage_cycle_5)) + geom_point() + theme_few() 
plot_grid(plot_acetate, plot_temp, align='h', labels=c('a', 'b'))

```
Is there a better point in time to analyze this data? Let's run this against multiple time points and find which creates the best model.
```{r apply p value to multiple cycles}
all_p_values <- as.data.frame(matrix(NA,ncol(data_training)-4,7))

packages(broom) 


# Start loop
for(i in 5:ncol(data_training)){
model <- rsm(data_training[,i] ~ SO(temp, acetate), data = data_training)
all_p_values[i-4,] <- c(colnames(data_training)[i],as.numeric(tidy(model)$p.value)) # get coefficient table as a data frame https://stackoverflow.com/questions/31570440/extract-regression-p-value-in-r
}
#End Loop

# Append column names
colnames(all_p_values) <- c("Time",tidy(model)$term)
all_p_values

# Turn character into numbers
all_p_values[,2:7] <- as.numeric(unlist(all_p_values[,2:7]))

#Reshape
packages(reshape2)
all_p_values <- melt(all_p_values)

# Plot
ggplot(data=all_p_values, aes(Time,value, group=variable)) + 
  geom_line(aes(color=variable))+
  geom_point(aes(color=variable))+
  xlab("Cycle")+
  ylab("p value")+
  geom_hline(yintercept = .05)
  # +   scale_x_date(format = "%b-%Y") + xlab("") + ylab("Daily Views")
```
Now let's load in all the cycle 5 data so far.
```{r all cycle 5 timepoints}
# import data
cycle_5_data <- as.data.frame(read.csv("cycle_5_data.csv"))
# get into correct form
# remove first two columns
cycle_5_data <- cycle_5_data[,-c(1:2)]

#transpose
# first remember the names
n <- cycle_5_data[,1]
cycle_5_data <- as.data.frame(t(cycle_5_data[,-1]))
colnames(cycle_5_data) <- n
cycle_5_data$myfactor <- factor(row.names(cycle_5_data))



#knit to past data
cycle_5_rsm <- cbind(data[,c(1:4)],cycle_5_data)

#Take out rows 14 and 15
cycle_5_rsm <- cycle_5_rsm[-c(14:15),]

# last col seems to contain row names. take out
cycle_5_rsm <- cycle_5_rsm[,-922]

# Previous code
# Create blank matrix to fill in with p values
all_p_values <- as.data.frame(matrix(NA,ncol(cycle_5_rsm)-4,7))

packages(broom) 


# Start loop
for(i in 5:ncol(cycle_5_rsm)){
model <- rsm(cycle_5_rsm[,i] ~ SO(temp, acetate), data = cycle_5_rsm)
all_p_values[i-4,] <- c(colnames(cycle_5_rsm)[i],as.numeric(tidy(model)$p.value)) # get coefficient table as a data frame https://stackoverflow.com/questions/31570440/extract-regression-p-value-in-r
}
#End Loop

# Append column names
colnames(all_p_values) <- c("Time",tidy(model)$term)
all_p_values

# Turn character into numbers
all_p_values[,2:7] <- as.numeric(unlist(all_p_values[,2:7]))

#Reshape
packages(reshape2)
all_p_values <- melt(all_p_values)

# Plot
ggplot(data=all_p_values, aes(Time,value, group=variable)) + 
  geom_line(aes(color=variable))+
  geom_point(aes(color=variable))+
  xlab("Cycle 5 time point")+
  ylab("p value")+
  geom_hline(yintercept = .05)

```
Wow let's zoom in on that recent time period where a couple of terms become significant.
```{r recent cycle 5}
all_p_values$Time <- as.numeric(all_p_values$Time)

ggplot(data=all_p_values, aes(Time,value, group=variable)) + 
  geom_line(aes(color=variable))+
  geom_point(aes(color=variable))+
  xlab("Cycle 5 time point")+
  ylab("p value")+
  geom_hline(yintercept = .05)+
  xlim(43001,NA)
```
Wow now let's zoom in even more.
```{r recent cycle 5 zoom}
all_p_values$Time <- as.numeric(all_p_values$Time)

ggplot(data=all_p_values, aes(Time,value, group=variable)) + 
  geom_line(aes(color=variable))+
  geom_point(aes(color=variable))+
  xlab("Cycle 5 time point")+
  ylab("p value")+
  geom_hline(yintercept = .05)+
  xlim(43003,NA)
```
What happens if we do an RSM with the most recent data?
```{r RSM voltage_cycle_5 recent}
rsm5 <- rsm(cycle_5_rsm[,ncol(cycle_5_rsm)-3] ~ SO(temp, acetate), data = cycle_5_rsm)
summary(rsm5)
persp(rsm5, ~ temp + acetate, col = rainbow(50), contours = "colors")
contour(rsm5, ~ temp + acetate, col = rainbow(50), contours = "colors")

#Look at slices against each factor
plot_acetate <- ggplot(data_training, aes(acetate, voltage_cycle_5)) + geom_point() + theme_few()
plot_temp <- ggplot(data_training, aes(temp, voltage_cycle_5)) + geom_point() + theme_few() 
plot_grid(plot_acetate, plot_temp, align='h', labels=c('a', 'b'))

```
Great let's transform the voltage data to power data given that the external voltage was constant at 1000 ohms.
```{r}
#Power in Watts
resistance <- 1000
myData <- cycle_5_rsm

myData[,5:ncol(myData)] <- myData[,5:ncol(myData)]^2/resistance #voltage squared divided by resistance

# RSM
rsm5 <- rsm(myData[,ncol(myData)-3] ~ SO(temp, acetate), data = myData)
summary(rsm5) # throws an error here
# persp(rsm5, ~ temp + acetate, col = rainbow(50), contours = "colors")
# contour(rsm5, ~ temp + acetate, col = rainbow(50), contours = "colors")
# 
# #Look at slices against each factor
# plot_acetate <- ggplot(data_training, aes(acetate, voltage_cycle_5)) + geom_point() + theme_few()
# plot_temp <- ggplot(data_training, aes(temp, voltage_cycle_5)) + geom_point() + theme_few() 
# plot_grid(plot_acetate, plot_temp, align='h', labels=c('a', 'b'))
```
Let's see if we can import our COD data. Did COD reduction differ significantly between units or across cycles?
```{r}
#Import
packages(readr)
cod <- read_csv("cod_results.csv",col_types = cols(MFC = "c"))
cod
#get in long format. Columns: mfcNumber, cycleNumber, endCOD, CODReductionPercent
cod <- melt(cod)
names(cod)[names(cod) == 'variable'] <- 'cycle'
names(cod)[names(cod) == 'MFC'] <- 'mfc'
names(cod)[names(cod) == 'value'] <- 'cod_mg_L'
cod$cod_mg_L <- cod$cod_mg_L*100
head(cod)

initial_cod <- 42067
cod$delta_cod_mg_L <- initial_cod-cod$cod_mg_L
cod$reduction_percent <- cod$delta_cod_mg_L/initial_cod

# plot
ggplot(data=cod, aes(x = cycle,reduction_percent, group=mfc)) + 
  geom_line(aes(color=mfc))+
  geom_point(aes(color=mfc))+
  xlab("Cycle")+
  ylab("COD Reduction (%)")
# run analysis
write_csv(cod,"cod_output_from_R.csv")
cod$cycle <- as.numeric(cod$cycle)
model <- lm(reduction_percent~mfc*cycle,data = cod)
anova(model)

```

```{r anova on just reduction percent fit to cycle}
cod$cycle <- as.factor(cod$cycle)
# 
# Fit a model using the lm function and look at the parameter estimates and standard errors for the treatment effects
  # https://www.r-bloggers.com/one-way-analysis-of-variance-anova/
  model = lm(reduction_percent ~ cycle, data = cod)
  # We save the model fitted to the data in an object so that we can undertake various actions to study the goodness of the fit to the data and other model assumptions. 
  # summary(model)
  # An analysis of variance table for this model can be produced via the anova command
  anova.model = anova(model)
  anova.model
  
  
# Alternative method (http://personality-project.org/r/r.guide/r.anova.html)
  aov_model = aov(reduction_percent ~ cycle, data = cod)  #do the analysis of variance
  cat("\n")
  summary(aov_model)                                    #show the summary table
  cat("\n")
  print(model.tables(aov_model,"means"),digits=3)       #report the means and the number of subjects/cell
  
# Interpret the Omnibus ANOVA Test Results  
  pvaluecolumn <- anova.model$"Pr(>F)" # Extracts p RA_cluster_in_label column
  pvalue = pvaluecolumn[1] # Extracts first row from p RA_cluster_in_label column
  cat("\n")
  cat("ANOVA p value is",pvalue,"\n") # Displays p value
  if (pvalue>.05) {
    writeLines("Results are not significant. Fail to reject null hypothesis.")
  } else {
    writeLines("Results are significant. Reject null hypothesis.")
  }

# Run Post-Hoc Tukey HSD between treatment groups
  cat("\n")
 
TukeyHSD(aov_model)
```
Does Cycle 5 COD reduction percent fit to our response surface? It doesn't seem to.
```{r}
# get cycle 5 cod data
rsm_cols <- data[,-c(5:ncol(data))]

cycle_5_rsm <- cbind(rsm_cols,cod$reduction_percent[cod$cycle %in% 5])
colnames(cycle_5_rsm)[5] <- "cod_reduction_percent"

#Build model
cycle_5_rsm_training <- cycle_5_rsm[-c(14:15),]
rsmModel <- rsm(cod_reduction_percent ~ SO(temp, acetate), data = cycle_5_rsm_training)
summary(rsmModel)
persp(rsmModel, ~ temp + acetate, col = rainbow(50), contours = "colors")
contour(rsmModel, ~ temp + acetate, col = rainbow(50), contours = "colors")

#Look at slices against each factor
plot_acetate <- ggplot(cycle_5_rsm_training, aes(acetate, cod_reduction_percent)) + geom_point() + theme_few()
plot_temp <- ggplot(cycle_5_rsm_training, aes(temp, cod_reduction_percent)) + geom_point() + theme_few()
plot_grid(plot_acetate, plot_temp, align='h', labels=c('a', 'b'))
```
Did time periods differ for each cycle? Maybe we should normalize by cod reduction per day, then rerun analysis.
```{r get cycle times}
library(lubridate)
cycleTimes <- read_csv("cycleTimes.csv")
cycleTimes$start <- mdy(cycleTimes$start)
cycleTimes$end <- mdy(cycleTimes$end)
cycleTimes$duration_days <- cycleTimes$end-cycleTimes$start
```

```{r analyze with cod reduction normalized to cycle times}
cod <- as_tibble(cod)
cod$cycle_duration <- unlist(cycleTimes[match(cod$cycle,cycleTimes$cycle),"duration_days"])
packages(tibbletime)
cod$delta_cod_mg_L_day <- cod$delta_cod_mg_L/cod$cycle_duration

#plot
ggplot(data=cod, aes(x = cycle,delta_cod_mg_L_day, group=mfc)) + 
  geom_line(aes(color=mfc))+
  geom_point(aes(color=mfc))+
  xlab("Cycle")+
  ylab("COD Reduction (mg/L/day)")

# run analysis
write_csv(cod,"cod_output_from_R_time_normalized.csv")
cod$cycle <- as.numeric(cod$cycle)
model <- lm(delta_cod_mg_L_day~mfc*cycle,data = cod)
anova(model)

# try data transformation
# check for normality
hist(cod$delta_cod_mg_L_day)
packages(ggpubr)
ggqqplot(cod$delta_cod_mg_L_day)
shapiro.test(cod$delta_cod_mg_L_day) # if p<.05, reject null hypothesis that data is normal, there is evidence data not normal

#preprocess
packages(caret)
packages(e1071)
trans = preProcess(data.frame(cod[,"delta_cod_mg_L_day"]), c("BoxCox", "center", "scale"))
cod_trans = data.frame(trans = predict(trans, data.frame(cod[,"delta_cod_mg_L_day"])))
# Visualize again
hist(unlist(cod_trans))
ggqqplot(unlist(cod_trans))
shapiro.test(unlist(cod_trans))
# Attach transformed variables to data set
colnames(cod_trans) <- "trans_delta_cod_mg_L_day"
cod <- cbind(cod,cod_trans)
write_csv(cod,"cod_output_from_R.csv")
# analyze
trans_model <- lm(trans_delta_cod_mg_L_day~mfc*cycle,data = cod)
anova(trans_model)
```
The transformed is essentially the same results as the initial delta cod mg/L/day. Regardless of transformation, it seems that COD doesn't differ significantly across MFC or cycle number when normalized to cycle time. However, anova on delta cod mg/L/day to MFC is not significant, while anova on delta cod mg/L/day to cycle as a nominal variable is significant. It seems Cycles 1, 2, and 5 experienced significantly higher COD reductions than cycles 3 and 4 as a group. Not sure why this happened. 

Does Cycle 5 COD reduction (delta_cod_mg_L_day) fit to our response surface?
```{r}
#attach relevant data
cycle_5_rsm <- cbind(rsm_cols,cod$delta_cod_mg_L_day[cod$cycle %in% 5])
colnames(cycle_5_rsm)[5] <- "delta_cod_mg_L_day"

#Build model
cycle_5_rsm_training <- cycle_5_rsm[-c(14:15),] #take off validation points
rsmModel <- rsm(delta_cod_mg_L_day ~ SO(temp, acetate), data = cycle_5_rsm_training)
summary(rsmModel)
persp(rsmModel, ~ temp + acetate, col = rainbow(50), contours = "colors")
contour(rsmModel, ~ temp + acetate, col = rainbow(50), contours = "colors")

#Look at slices against each factor
plot_acetate <- ggplot(cycle_5_rsm_training, aes(acetate, delta_cod_mg_L_day)) + geom_point() + theme_few()
plot_temp <- ggplot(cycle_5_rsm_training, aes(temp, delta_cod_mg_L_day)) + geom_point() + theme_few()
plot_grid(plot_acetate, plot_temp, align='h', labels=c('a', 'b'))
```
It looks like the cycle 5 delta_cod_mg_L_day doesn't fit to the response surface either. So the higher voltages seen in response to temperature and acetate must be due to either enhanced efficiency of bioelectrochemical activity by the biofilm or pure noise.

Now let's pull in all the voltage data over all times. Then we can integrate to find coulombic efficiency.
```{r pull in all voltage data}
voltage_data <- rbind(read_csv('voltage_1.csv'),read_csv('voltage_2.csv'))
voltage_data <- voltage_data[,-18] #lop off channel 16 which wasn't used
voltage_data$Date <- mdy(voltage_data$Date)
voltage_data$dateTime <- with(voltage_data, ymd(voltage_data$Date) + hms(voltage_data$Time)) #https://stackoverflow.com/questions/11609252/r-tick-data-merging-date-and-time-into-a-single-object

voltage_data <- select(voltage_data,dateTime,everything()) #move dateTime to front
voltage_data$dateTime <- as.POSIXct(voltage_data$dateTime)

voltage_data <- voltage_data[order(voltage_data$dateTime),] #make sure in order

# double check this worked - do any times not match with their date times?
voltage_data[format(voltage_data$dateTime, "%H:%M:%S") != format(voltage_data$Time, "%H:%M:%S"),] # everything matches up

# remove bad data from voltage collector crashing
voltage_data <- voltage_data[year(voltage_data$dateTime) < 2018,]
#We missed some data when the picologger crashed. Let's interpolate around 9/20/2017.
voltage_data[voltage_data$Date < "2017-09-21" & voltage_data$Date > "2017-09-18",]
plot(voltage_data[voltage_data$Date > "2017-09-18" & voltage_data$Date < "2017-09-21","dateTime"])
# Looks like 6000 duplicate rows when it crashed. Let's remove those first then interpolate.
plot(voltage_data[voltage_data$Date > "2017-09-18" & voltage_data$Date < "2017-09-21","dateTime"])
plot(voltage_data[which(duplicated(voltage_data$dateTime)),"dateTime"])
plot(voltage_data[-which(duplicated(voltage_data$dateTime)),"dateTime"])
voltage_data <- voltage_data[-which(duplicated(voltage_data$dateTime)),]

# remove 2017-09-19 04:33:22 thru 2017-09-19 04:40:22
voltage_data <- voltage_data[-which(format(voltage_data$Time, "%H:%M:$S") >= "04:33:22" & format(voltage_data$Time, "%H:%M:$S") <= "04:40:22"),]
plot(voltage_data[voltage_data$Date > "2017-09-18" & voltage_data$Date < "2017-09-21","dateTime"])

#Now let's interpolate between our missing times.

# between 2017-09-19 04:32:22 and 2017-09-20 10:21:51
test <- voltage_data[voltage_data$Date > "2017-09-18" & voltage_data$Date < "2017-09-21",]
test_melt <- gather(test,"mfc","voltage",4:ncol(voltage_data))

#Visualize
ggplot(data=test_melt, aes(x = dateTime,y = voltage, group=mfc)) + 
  geom_line(aes(color=mfc))+
  geom_point(aes(color=mfc))+
  xlab("Time")+
  ylab("Voltage (V)")

#interpolate test data set
packages(padr)
test$dateTime <- as.POSIXct(format(test$dateTime, "%Y-%m-%d %H:%M:00")) #strip off seconds so padr doesn't get confused
test$dateTime[15] <- as.POSIXct("2017-09-20 10:32:00")
paddedTime <- test %>% pad(interval="20 min",by = 'dateTime',start_val=as.POSIXct("2017-09-19 04:32:00"),end_val=as.POSIXct("2017-09-20 10:32:00"))
paddedTime <- paddedTime[-1,] #remove first row
paddedTime <- paddedTime[-nrow(paddedTime),]

#put paddedTime back into test data frame
test <- rbind(test,paddedTime)
test <- test[order(test$dateTime),] #it works

#put paddedTime back into voltage_data data frame
# are there any NAs currently in voltage_data?
voltage_data[is.na(voltage_data$Date),] #don't seem to be
voltage_data[format(voltage_data$dateTime, "%H:%M:%S") != format(voltage_data$Time, "%H:%M:%S"),] # works fine here
```

```{r}
voltage_data <- bind_rows(paddedTime,voltage_data) # bind together - this is where it goes wrong. Times and dateTimes no longer match.
voltage_data[1:89,1] <- voltage_data[1:89,1] - 7*60*60 #workaround
voltage_data <- voltage_data[order(voltage_data$dateTime),]
# fill with polynomial interpolation
packages(zoo)
voltage_data[,c(4:ncol(voltage_data))] <- na.approx(voltage_data[,c(4:ncol(voltage_data))])
#visualize
# between 2017-09-19 04:32:22 and 2017-09-20 10:21:51
test <- voltage_data[voltage_data$dateTime > as.Date("2017-09-18") & voltage_data$dateTime < as.Date("2017-09-21"),]
test_melt <- gather(test,"mfc","voltage",4:ncol(voltage_data))
#Visualize
ggplot(data=test_melt, aes(x = dateTime,y = voltage, group=mfc)) + 
  geom_line(aes(color=mfc))+
  geom_point(aes(color=mfc))+
  xlab("Time")+
  ylab("Voltage (V)")
# Visualize whole data set
test_melt <- gather(voltage_data,"mfc","voltage",4:ncol(voltage_data))
ggplot(data=test_melt, aes(x = dateTime,y = voltage, group=mfc)) + 
  geom_line(aes(color=mfc))+
  geom_point(aes(color=mfc))+
  xlab("Time")+
  ylab("Voltage (V)")
# nice work!
```

Now let's apply cycle numbers to the voltage_data set to calculate power production over each cycle and MFC as well as coulombic efficiency for each cycle and MFC.
```{r}
# Find points in voltage_data where voltage is 0, use those as time points for marking distinct cycles
cycleTimes$end <- as.POSIXct(c("2017-08-07 15:52:22", "2017-08-15 11:12:22", "2017-08-29 10:52:22", "2017-09-11 15:32:22", "2017-09-26 16:01:51"))
#lookup 
voltage_data <- cbind(voltage_data,cycleTimes[match(voltage_data$dateTime,cycleTimes$end),"cycle"])
voltage_data[!is.na(voltage_data$cycle),]
voltage_data$cycle[nrow(voltage_data)] <- 5
# fill up
voltage_data$cycle <- as.numeric(voltage_data$cycle)
voltage_data %>% fill(cycle, .direction = "up") -> voltage_data
# move
voltage_data <- select(voltage_data,dateTime,cycle,everything())
#remove date and time because it seems to just be causing issues
voltage_data <- select(voltage_data,everything(),-Date,-Time)
```
Next let's calculate power production for each mfc for each cycle. Then we can do some analysis on that before moving to coulombic efficiency.
```{r}
voltage_melt <- gather(voltage_data,"mfc","voltage",3:ncol(voltage_data)) 
power_melt <- voltage_melt
power_melt <- power_melt[,-ncol(power_melt)]
power_melt$power_J_s <- voltage_melt$voltage^2/resistance
power_melt <- as.tibble(power_melt)
#integrate for power output or energy in Joules
power_output <- ddply(power_melt, .(cycle, mfc), summarize, energy_J = trapz(as.numeric(dateTime),power_J_s))
#check it worked
# it did - checked in excel
#visualize
ggplot(data=power_output, aes(x = cycle,y = energy_J, group=mfc)) + 
  geom_line(aes(color=mfc))+
  geom_point(aes(color=mfc))+
  xlab("Cycle")+
  ylab("Energy produced (J)")

#analysis
power_output %>% lm(energy_J~cycle*mfc,.) %>% anova()
#cycle seems highly signficant
power_output %>% lm(energy_J~cycle,.) %>% anova()
summary(aov(energy_J~as.factor(cycle),data=power_output))
TukeyHSD(aov(energy_J~as.factor(cycle),data=power_output))
#mfc doesn't have a significant effect on power output
plot(power_output$mfc,power_output$energy_J)
summary(aov(energy_J~mfc,data=power_output))
#fit power output for each cycle to response surface
power_output %>% spread(.,cycle,energy_J) -> power_output_spread
power_output_spread[order(as.numeric(power_output_spread$mfc)),] -> power_output_spread
cbind(rsm_cols,power_output_spread[,-1])->power_output_rsm

# Create blank matrix to fill in with p values
all_p_values <- as.data.frame(matrix(NA,ncol(power_output_rsm)-4,7))
packages(broom) 

# Start loop
for(i in 5:ncol(power_output_rsm)){
model <- rsm(power_output_rsm[,i] ~ SO(temp, acetate), data = power_output_rsm)
all_p_values[i-4,] <- c(colnames(power_output_rsm)[i],as.numeric(tidy(model)$p.value)) # get coefficient table as a data frame https://stackoverflow.com/questions/31570440/extract-regression-p-value-in-r
}
#End Loop

# Append column names
colnames(all_p_values) <- c("Time",tidy(model)$term)
all_p_values

# Turn character into numbers
all_p_values[,2:7] <- as.numeric(unlist(all_p_values[,2:7]))

#Reshape
packages(reshape2)
all_p_values <- melt(all_p_values)

# Plot
ggplot(data=all_p_values, aes(Time,value, group=variable)) + 
  geom_line(aes(color=variable))+
  geom_point(aes(color=variable))+
  xlab("Cycle 5 time point")+
  ylab("p value")+
  geom_hline(yintercept = .05)

#What about cycle 5? Power output in joules was not significant.
rsm(power_output_rsm[,"5"] ~ SO(temp, acetate), data = power_output_rsm) %>% tidy()
#fit cumulative power to response surface
power_output_rsm$cumulative <- rowSums(power_output_rsm[,5:9])
rsm <- rsm(power_output_rsm[,"cumulative"] ~ SO(temp, acetate), data = power_output_rsm)
summary(rsm)
persp(rsm, ~ temp + acetate, col = rainbow(50), contours = "colors")
```
Note that temperature has a highly significant effect on cumulative power output across all cycles.

Next let's try transforming the power output data and seeing if results differ.
```{r}
# #visualize
# hist(power_output$energy_J)
# packages(ggpubr)
# ggqqplot(power_output$energy_J)
# shapiro.test(power_output$energy_J) # if p<.05, reject null hypothesis that data is normal, there is evidence data not normal
# #preprocess
# packages(caret)
# packages(e1071)
# trans = preProcess(data.frame(power_output[,"energy_J"]), c("BoxCox", "center", "scale"))
# power_trans = data.frame(trans = predict(trans, data.frame(power_output[,"energy_J"])))
# # Visualize again
# hist(unlist(power_trans))
# ggqqplot(unlist(power_trans))
# shapiro.test(unlist(power_trans))
# # Attach transformed variables to data set
# colnames(power_trans) <- "energy_J"
# power_output <- cbind(power_output[,-ncol(power_output)],power_trans)
```
Redo analysis with transformed variables
```{r}
# #analysis
# power_output %>% lm(energy_J~cycle*mfc,.) %>% anova()
# #cycle seems highly signficant
# power_output %>% lm(energy_J~cycle,.) %>% anova()
# summary(aov(energy_J~as.factor(cycle),data=power_output))
# TukeyHSD(aov(energy_J~as.factor(cycle),data=power_output))
# #mfc doesn't have a significant effect on power output
# plot(power_output$mfc,power_output$energy_J)
# summary(aov(energy_J~mfc,data=power_output))
# #fit power output for each cycle to response surface
# power_output %>% spread(.,cycle,energy_J) -> power_output_spread
# power_output_spread[order(as.numeric(power_output_spread$mfc)),] -> power_output_spread
# cbind(rsm_cols,power_output_spread[,-1])->power_output_rsm
# 
# # Create blank matrix to fill in with p values
# all_p_values <- as.data.frame(matrix(NA,ncol(power_output_rsm)-4,7))
# packages(broom) 
# 
# # Start loop
# for(i in 5:ncol(power_output_rsm)){
# model <- rsm(power_output_rsm[,i] ~ SO(temp, acetate), data = power_output_rsm)
# all_p_values[i-4,] <- c(colnames(power_output_rsm)[i],as.numeric(tidy(model)$p.value)) # get coefficient table as a data frame https://stackoverflow.com/questions/31570440/extract-regression-p-value-in-r
# }
# #End Loop
# 
# # Append column names
# colnames(all_p_values) <- c("Time",tidy(model)$term)
# all_p_values
# 
# # Turn character into numbers
# all_p_values[,2:7] <- as.numeric(unlist(all_p_values[,2:7]))
# 
# #Reshape
# packages(reshape2)
# all_p_values <- melt(all_p_values)
# 
# # Plot
# ggplot(data=all_p_values, aes(Time,value, group=variable)) + 
#   geom_line(aes(color=variable))+
#   geom_point(aes(color=variable))+
#   xlab("Cycle 5 time point")+
#   ylab("p value")+
#   geom_hline(yintercept = .05)
# 
# #What about cycle 5? Power output in joules was not significant.
# rsm(power_output_rsm[,"5"] ~ SO(temp, acetate), data = power_output_rsm) %>% summary()
# #fit cumulative power to response surface
# power_output_rsm$cumulative <- rowSums(power_output_rsm[,5:9])
# rsm <- rsm(power_output_rsm[,"cumulative"] ~ SO(temp, acetate), data = power_output_rsm)
# summary(rsm)
# persp(rsm, ~ temp + acetate, col = rainbow(50), contours = "colors")
```
Essentially the same results whether energy in J is transformed or not. 

Next let's work on coulombic efficiency calculation and analysis.
```{r calculate coulombic efficiency}
#desired output: long format table "ce_long" with columns cycle, mfc, ce
#inputs: COD reduction, current = voltage/resistance
voltage_melt %>% mutate(current_A=voltage/resistance) %>% select(everything(),-voltage) -> current_melt
current_output <- ddply(current_melt, .(cycle, mfc), summarize, charge_C = trapz(as.numeric(dateTime),current_A))
#using dplyr
  # current_melt %>% group_by(cycle,mfc) %>% select(dateTime,current_A) %>% summarise_each(funs(charge_C=trapz(as.numeric(dateTime),current_A)))

current_output$mfc <- as.numeric(current_output$mfc)
current_output[with(current_output, order(current_output$cycle,current_output$mfc)),] %>% select(mfc,everything()) -> current_output
#calc CE = (M*Idt)/(F*b*van*COD_Reduction_gL)
M=	32
F=	96485.33289
b=	4
van=	0.03
mgL_gL= .001
current_output %>% mutate(ce = (M*charge_C)/(F*b*van*cod$delta_cod_mg_L*mgL_gL)) -> current_output

```

```{r analyze CE}
#visualize
hist(current_output$ce)
packages(ggpubr)
ggqqplot(current_output$ce)
shapiro.test(current_output$ce) # if p<.05, reject null hypothesis that data is normal, there is evidence data not normal
#preprocess
packages(caret)
packages(e1071)
trans = preProcess(data.frame(current_output[,"ce"]), c("BoxCox", "center", "scale"))
ce_trans = data.frame(trans = predict(trans, data.frame(current_output[,"ce"])))
# Visualize again
hist(unlist(ce_trans))
ggqqplot(unlist(ce_trans))
shapiro.test(unlist(ce_trans))
# Attach transformed variables to data set
colnames(ce_trans) <- "ce_trans"
current_output <- cbind(current_output,ce_trans)


#fit data for each cycle to response surface
current_output -> data
data %>% select(mfc,cycle,ce_trans) %>% spread(.,cycle,ce_trans) -> data_spread
data_spread[order(as.numeric(data_spread$mfc)),] -> data_spread
cbind(rsm_cols,power_output_spread[,-1]) -> data_rsm

# Create blank matrix to fill in with p values
all_p_values <- as.data.frame(matrix(NA,ncol(data_rsm)-4,7))
packages(broom) 

# Start loop
for(i in 5:ncol(data_rsm)){
model <- rsm(data_rsm[,i] ~ SO(temp, acetate), data = data_rsm)
all_p_values[i-4,] <- c(colnames(data_rsm)[i],as.numeric(tidy(model)$p.value)) # get coefficient table as a data frame https://stackoverflow.com/questions/31570440/extract-regression-p-value-in-r
}
#End Loop

# Append column names
colnames(all_p_values) <- c("cycle",tidy(model)$term)

# Turn character into numbers
all_p_values[,2:7] <- as.numeric(unlist(all_p_values[,2:7]))

#Reshape
packages(reshape2)
all_p_values <- melt(all_p_values)

# Plot
ggplot(data=all_p_values, aes(cycle,value, group=variable)) + 
  geom_line(aes(color=variable))+
  geom_point(aes(color=variable))+
  xlab("Cycle")+
  ylab("p value")+
  geom_hline(yintercept = .05)
```
Why aren't the p values the same for Cycle 5?

Let's try analyzing charge_C as well.
```{r}


```

